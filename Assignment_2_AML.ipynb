{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import models, layers\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Load the data\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "maxlen = 500  # Cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 32\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to ensure each input has the same length\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Model with one hidden layer\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(max_features, 32, input_length=maxlen))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))  # One hidden layer\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy with one hidden layer: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEB-yF1WU5tp",
        "outputId": "40be8f33-62c8-403e-c64d-d575b2171cc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.6578 - loss: 0.5779 - val_accuracy: 0.8666 - val_loss: 0.3175\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.9227 - loss: 0.1994 - val_accuracy: 0.8488 - val_loss: 0.3638\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9794 - loss: 0.0665 - val_accuracy: 0.8486 - val_loss: 0.4573\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9967 - loss: 0.0152 - val_accuracy: 0.8376 - val_loss: 0.6558\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.8408 - val_loss: 0.7791\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.9999 - loss: 4.2081e-04 - val_accuracy: 0.8402 - val_loss: 0.8605\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9999 - loss: 3.2229e-04 - val_accuracy: 0.8414 - val_loss: 0.9179\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.9998 - loss: 6.0706e-04 - val_accuracy: 0.8446 - val_loss: 0.9210\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 3.7749e-05 - val_accuracy: 0.8436 - val_loss: 0.9419\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 2.9471e-05 - val_accuracy: 0.8428 - val_loss: 0.9617\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 0.9130\n",
            "Test accuracy with one hidden layer: 0.8410400152206421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Using 64 units in one hidden layer\n",
        "model_units = models.Sequential()\n",
        "model_units.add(layers.Embedding(max_features, 32, input_length=maxlen))\n",
        "model_units.add(layers.Flatten())\n",
        "model_units.add(layers.Dense(64, activation='relu'))  # 64 hidden units\n",
        "model_units.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile and train as usual\n",
        "model_units.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_units = model_units.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)\n",
        "test_loss_units, test_acc_units = model_units.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy with 64 hidden units: {test_acc_units}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHgiuaRxWe-3",
        "outputId": "4a768c45-ff92-48d4-89b7-ffcac6286cc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.6489 - loss: 0.5815 - val_accuracy: 0.8564 - val_loss: 0.3259\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.9292 - loss: 0.1848 - val_accuracy: 0.8566 - val_loss: 0.3490\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.9863 - loss: 0.0502 - val_accuracy: 0.8468 - val_loss: 0.5097\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9972 - loss: 0.0110 - val_accuracy: 0.8380 - val_loss: 0.6652\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.8384 - val_loss: 0.8079\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 7.9073e-04 - val_accuracy: 0.8386 - val_loss: 0.8844\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.3351e-04 - val_accuracy: 0.8374 - val_loss: 0.9264\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.7540e-05 - val_accuracy: 0.8352 - val_loss: 0.9540\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0144e-05 - val_accuracy: 0.8352 - val_loss: 0.9708\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.8416 - val_loss: 0.9552\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 0.9449\n",
            "Test accuracy with 64 hidden units: 0.8386800289154053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with mse loss\n",
        "model_mse = models.Sequential()\n",
        "model_mse.add(layers.Embedding(max_features, 32, input_length=maxlen))\n",
        "model_mse.add(layers.Flatten())\n",
        "model_mse.add(layers.Dense(32, activation='relu'))\n",
        "model_mse.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile with mse loss function\n",
        "model_mse.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "# Train and evaluate\n",
        "history_mse = model_mse.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)\n",
        "test_loss_mse, test_acc_mse = model_mse.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy with mse loss: {test_acc_mse}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoBpRM4vXQB9",
        "outputId": "73ed6800-0fb0-4bbf-e8b4-5bbede2bf977"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - accuracy: 0.6336 - loss: 0.2130 - val_accuracy: 0.8494 - val_loss: 0.1066\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9088 - loss: 0.0709 - val_accuracy: 0.8388 - val_loss: 0.1150\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.9677 - loss: 0.0283 - val_accuracy: 0.8440 - val_loss: 0.1198\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9894 - loss: 0.0108 - val_accuracy: 0.8412 - val_loss: 0.1240\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9960 - loss: 0.0044 - val_accuracy: 0.8354 - val_loss: 0.1314\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.9965 - loss: 0.0035 - val_accuracy: 0.8386 - val_loss: 0.1325\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9976 - loss: 0.0024 - val_accuracy: 0.8360 - val_loss: 0.1344\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0023 - val_accuracy: 0.8262 - val_loss: 0.1390\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0019 - val_accuracy: 0.8286 - val_loss: 0.1376\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.9989 - loss: 0.0012 - val_accuracy: 0.8302 - val_loss: 0.1376\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.1409\n",
            "Test accuracy with mse loss: 0.828279972076416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with tanh activation\n",
        "model_tanh = models.Sequential()\n",
        "model_tanh.add(layers.Embedding(max_features, 32, input_length=maxlen))\n",
        "model_tanh.add(layers.Flatten())\n",
        "model_tanh.add(layers.Dense(32, activation='tanh'))  # tanh activation\n",
        "model_tanh.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_tanh.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train and evaluate\n",
        "history_tanh = model_tanh.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)\n",
        "test_loss_tanh, test_acc_tanh = model_tanh.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy with tanh activation: {test_acc_tanh}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIlMPUaiYLjP",
        "outputId": "4a95f1d0-4d28-47b1-b070-186a950b6820"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.6984 - loss: 0.5521 - val_accuracy: 0.8626 - val_loss: 0.3213\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.9354 - loss: 0.1704 - val_accuracy: 0.8492 - val_loss: 0.3918\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.9904 - loss: 0.0380 - val_accuracy: 0.8462 - val_loss: 0.5672\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.8370 - val_loss: 0.8003\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 5.0297e-04 - val_accuracy: 0.8390 - val_loss: 0.8884\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.7158e-04 - val_accuracy: 0.8336 - val_loss: 0.9381\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9997 - loss: 7.2065e-04 - val_accuracy: 0.8300 - val_loss: 0.9631\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 4.8476e-05 - val_accuracy: 0.8372 - val_loss: 0.9650\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.7985e-05 - val_accuracy: 0.8392 - val_loss: 0.9867\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.8938e-05 - val_accuracy: 0.8386 - val_loss: 0.9914\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.9355\n",
            "Test accuracy with tanh activation: 0.8335199952125549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with Dropout\n",
        "model_dropout = models.Sequential()\n",
        "model_dropout.add(layers.Embedding(max_features, 32, input_length=maxlen))\n",
        "model_dropout.add(layers.Flatten())\n",
        "model_dropout.add(layers.Dropout(0.5))  # Dropout layer\n",
        "model_dropout.add(layers.Dense(32, activation='relu'))\n",
        "model_dropout.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile and train\n",
        "model_dropout.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_dropout = model_dropout.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)\n",
        "test_loss_dropout, test_acc_dropout = model_dropout.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy with dropout: {test_acc_dropout}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbOcyttGZR2j",
        "outputId": "b4a5bb7f-29dd-45c5-fff0-a94cbfb403eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.6197 - loss: 0.6132 - val_accuracy: 0.8524 - val_loss: 0.3440\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8923 - loss: 0.2637 - val_accuracy: 0.8788 - val_loss: 0.3052\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.9395 - loss: 0.1615 - val_accuracy: 0.8718 - val_loss: 0.3315\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.9611 - loss: 0.1055 - val_accuracy: 0.8644 - val_loss: 0.3895\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9708 - loss: 0.0791 - val_accuracy: 0.8684 - val_loss: 0.4275\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.9782 - loss: 0.0604 - val_accuracy: 0.8688 - val_loss: 0.4798\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.9814 - loss: 0.0522 - val_accuracy: 0.8728 - val_loss: 0.4566\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9825 - loss: 0.0456 - val_accuracy: 0.8704 - val_loss: 0.4979\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9855 - loss: 0.0373 - val_accuracy: 0.8574 - val_loss: 0.5828\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9867 - loss: 0.0362 - val_accuracy: 0.8680 - val_loss: 0.5521\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.5331\n",
            "Test accuracy with dropout: 0.8656799793243408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers  # Import regularizers\n",
        "\n",
        "# Model with L2 regularization\n",
        "model_l2 = models.Sequential()\n",
        "model_l2.add(layers.Embedding(max_features, 32, input_length=maxlen))\n",
        "model_l2.add(layers.Flatten())\n",
        "model_l2.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)))  # L2 regularization\n",
        "model_l2.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile and train\n",
        "model_l2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_l2 = model_l2.fit(x_train, y_train, epochs=10, batch_size=batch_size, validation_split=0.2)\n",
        "test_loss_l2, test_acc_l2 = model_l2.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy with L2 regularization: {test_acc_l2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GGjriqBau14",
        "outputId": "ee9a8923-67d0-4c2c-b904-7cbe91d05dae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 22ms/step - accuracy: 0.6686 - loss: 0.6269 - val_accuracy: 0.8596 - val_loss: 0.3951\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9071 - loss: 0.3047 - val_accuracy: 0.8680 - val_loss: 0.3771\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.9604 - loss: 0.2014 - val_accuracy: 0.8558 - val_loss: 0.4299\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.9819 - loss: 0.1399 - val_accuracy: 0.8522 - val_loss: 0.4800\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9918 - loss: 0.0968 - val_accuracy: 0.8444 - val_loss: 0.5362\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.9950 - loss: 0.0770 - val_accuracy: 0.8494 - val_loss: 0.5545\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9957 - loss: 0.0685 - val_accuracy: 0.8450 - val_loss: 0.5915\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9960 - loss: 0.0657 - val_accuracy: 0.8430 - val_loss: 0.6151\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9965 - loss: 0.0593 - val_accuracy: 0.8422 - val_loss: 0.6551\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9960 - loss: 0.0625 - val_accuracy: 0.8456 - val_loss: 0.6822\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8420 - loss: 0.6626\n",
            "Test accuracy with L2 regularization: 0.8417199850082397\n"
          ]
        }
      ]
    }
  ]
}